{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c64bb194-5e4c-4849-ab09-22c4e4aa2a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ade5dd-f083-4715-b052-38e89d70641c",
   "metadata": {},
   "source": [
    "# We create a tensor with the required grad parameter because we want to keep track of the gradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "8170c0c7-82ec-4b71-90ca-11f5fa22437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=torch.tensor(1.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fab5ebcf-d40c-4c95-a9e8-4c6a688d6c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1., requires_grad=True)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "97536bca-3557-4f1d-bd19-894b49cc5451",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=3*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "96cb0272-925b-408b-ace7-3c82b5b72b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "94d132ad-5892-4630-b091-d46fb1d1725e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a555b33-c13a-4f94-9447-dac730d187e8",
   "metadata": {},
   "source": [
    "# dy/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2da12ebc-e408-463a-9a98-4db49a365ea3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de1b99c-af12-46af-8e62-2499042d2f8d",
   "metadata": {},
   "source": [
    "<img src=\"1.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196bde07-455c-4ff7-80ad-da3b7f81f74c",
   "metadata": {},
   "source": [
    "# A deeper network    (a*b)*d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4486bb2b-9dd5-40d9-b733-bf15c653dfa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a= torch.tensor(2.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d32c6157-a7b7-44dc-ae72-b00212e8380e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b= torch.tensor(3.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "16548ee9-2988-46f0-8d01-b41f60d928e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "499657c6-5060-44f8-b896-ea317f2772aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1ba2e0c3-62fa-42e0-a9af-5ee90cfe4ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "d= torch.tensor(4.0, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0c067576-1073-4b7c-82cb-60c85c22175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e=c*d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f34adf31-0056-4030-a714-ccce64a3b340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9533ad01-f45d-4c0e-b043-1ad62185fb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7801cc87-ae36-4d7a-bab1-41e0af449de0",
   "metadata": {},
   "source": [
    "# d(d)/ de"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1b9800ad-d781-49cd-9578-7f9fe1785f30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95cd7b5-440f-4546-9e10-49a2f720cd16",
   "metadata": {},
   "source": [
    "# da/de = de/dc * dc/da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b84d65bb-0a64-4a08-95ce-2b7c364cdfb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "232c65dd-6ae3-49bb-b4bb-ca943546261a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# db/de = de/dc * dc/db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "625bd715-0494-463e-959d-8dfa86a2fe50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4a3381-b205-403f-92b9-962444acbfb8",
   "metadata": {},
   "source": [
    "<img src=\"2.png\" alt=\"Alternative text\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6761059c-1592-49c6-80fa-3172b0c6df70",
   "metadata": {},
   "source": [
    "# We ran another pass but the grads are now different , that because it accumulates in grad variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "855f107d-dc44-4bf2-a8de-ca08835dc9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "e= (a*b)*d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f9a5f029-ecae-4ec2-85ce-a520134172ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24., grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e99e7116-0551-476b-99bc-fecaac4ec3d5",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[88], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43me\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\venv\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "bf9ac31b-9e75-406b-80fc-3b0c29978e74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(36.)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3b8ea641-0bd9-459a-9c77-18c944c7b49d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(24.)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "09476c37-ca4f-4b9c-aabc-5939049da4bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(18.)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb5a73b-d450-476f-a2ba-318ed09af32d",
   "metadata": {},
   "source": [
    "# We need to clear them before making forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1a8b4998-4ccf-497a-a69b-6d42442f1f47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad.zero_()\n",
    "b.grad.zero_()\n",
    "d.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b8a3f0e8-370f-4f00-9650-1b7941852220",
   "metadata": {},
   "outputs": [],
   "source": [
    "e= (a*b)*d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "f4bca805-3fac-4bf7-ab4c-09179f39245f",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "90c59de2-a4ba-46e6-89c1-60af9bb23c23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2f2f1c88-0d98-4752-8b16-6a4b537161f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(8.)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "d00597ed-3e26-4bff-bf13-40f6697ca8a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba4b980-963f-4007-80b8-aeb770f27e8c",
   "metadata": {},
   "source": [
    "# seems fine now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "f1d6a7eb-b591-40e8-a6bd-9601044ea37e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad.zero_()\n",
    "b.grad.zero_()\n",
    "d.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c671d163-ae43-4c59-8f9e-283fa32d9a40",
   "metadata": {},
   "source": [
    "# Lets Try Grad Calculation wrt c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "026c835d-6e5c-40a9-8afd-ba37924b33c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c= a*b\n",
    "e=c*d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "a1d6b896-f46a-4b39-8426-bd0536dfc941",
   "metadata": {},
   "outputs": [],
   "source": [
    "c.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5c7ce4b4-7dff-4212-a191-8fd213070b07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4e76b6a5-4050-4265-832c-5014a4cc76a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0bd58ddd-4c07-4dc4-84d6-5628cceb379f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fe233f-a792-4a15-b7aa-5254a9266bd2",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a835c47-fd09-4aa5-b076-95595009ed69",
   "metadata": {},
   "source": [
    "# Our gradients are working fine because we are having scalar inputs for now ,lets try the vector inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "9cd485fd-2ae2-4605-8cea-4e50863734a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.tensor([1.0,2.0,3.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "43a4c228-2196-4112-9691-5429e0f76576",
   "metadata": {},
   "outputs": [],
   "source": [
    "y=3*x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c3ea50e6-d2a5-4a78-8553-e0cf1745893b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 6., 9.], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "896e18e3-d892-411f-afa9-b9cbb7f16f8e",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[138], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43my\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\venv\\Lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:193\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    189\u001b[0m inputs \u001b[38;5;241m=\u001b[39m (inputs,) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(inputs, torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;28;01melse\u001b[39;00m \\\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28mtuple\u001b[39m(inputs) \u001b[38;5;28;01mif\u001b[39;00m inputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m()\n\u001b[0;32m    192\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[1;32m--> 193\u001b[0m grad_tensors_ \u001b[38;5;241m=\u001b[39m \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "File \u001b[1;32m~\\venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:88\u001b[0m, in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mrequires_grad:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m out\u001b[38;5;241m.\u001b[39mnumel() \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 88\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     89\u001b[0m     new_grads\u001b[38;5;241m.\u001b[39mappend(torch\u001b[38;5;241m.\u001b[39mones_like(out, memory_format\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mpreserve_format))\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[1;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "y.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1250a-f42e-41cc-9fcc-ea160827b139",
   "metadata": {},
   "source": [
    "# Answer is , Y takes a parameter in backward which is same shape as the output it produces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "53bd313d-2195-4025-8f0e-08c942ac1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward(torch.tensor([1.0,1.0,1.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1636f062-7e61-45b7-a0b1-11ac12b6885a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3., 3., 3.])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52b72d9-74ed-4de8-b26f-a79eeacdf3a8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87a3db6-b7d4-4d1d-a99a-b10a19a5ae0b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "cb1697d3-cbf1-4c0e-a993-17b38b862e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= torch.linspace(0,180,10, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "6573243a-b037-4faa-a2c8-d6094f18f38e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.,  20.,  40.,  60.,  80., 100., 120., 140., 160., 180.],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "d585bcf8-945e-4ab9-89e9-736c53980e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y= torch.sin(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "86b9a702-c2b1-4edd-9b9b-9d471eb0bc13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0000,  0.9129,  0.7451, -0.3048, -0.9939, -0.5064,  0.5806,  0.9802,\n",
       "         0.2194, -0.8012], grad_fn=<SinBackward0>)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "a5d897c5-acf9-4606-bc47-2d85d45b06db",
   "metadata": {},
   "outputs": [],
   "source": [
    "y.backward(torch.ones(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "5082b754-abc8-4aff-8041-571580bbc43e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  0.4081, -0.6669, -0.9524, -0.1104,  0.8623,  0.8142, -0.1978,\n",
       "        -0.9756, -0.5985])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f52657-1f61-4722-ae30-20482237c8d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
